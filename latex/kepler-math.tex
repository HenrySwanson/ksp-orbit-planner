\documentclass{article}
\usepackage{amsmath}
\usepackage{bm}

\newcommand{\dd}{\mathrm{d}}
\newcommand{\der}[2]{\frac{\dd #1}{\dd #2}}

\numberwithin{equation}{subsection}

\begin{document}
Here's the math behind this simulator. (heavily abbreviated).

TODO all the other math

\section{Universal Variable Formulation}

\subsection{Regularizing the Equation of Motion}

The equation of motion for our satellite is
\begin{equation}
\label{eq-of-motion-t}
\ddot{\bm x} + \frac{\mu}{r^3} \bm x = 0
\end{equation}

We introduce a new variable $s$ such that $\der{s}{t} = \frac{1}{r}$. Since dots are being used to represent derivatives with respect to $t$, we'll use primes to represent derivatives with respect to $s$. From the chain rule, we can derive the following relations for any state function $f$, which will be used repeatedly:
\begin{equation}
\label{s-and-t-derivatives}
\dot f = \frac{1}{r} f' \qquad \ddot f = \frac{r f'' - f' r'}{r^3}
\end{equation}

Using this, we rewrite (\ref{eq-of-motion-t}) in terms of $s$:
\begin{equation}
\label{eq-of-motion-s}
\bm x'' - \frac{r'}{r} \bm x' + \frac{\mu}{r} \bm x = 0
\end{equation}

This can be further simplified by introducing some conserved physical quantities. In particular, consider the eccentricity vector and the energy:
\begin{equation}
\label{eccentricity-and-energy}
e = \left( \frac{v^2}{\mu} - \frac{1}{r} \right) \bm x - \frac{\bm x \cdot \bm v}{\mu} \bm v \qquad E = \frac{v^2}{2} - \frac{\mu}{r}
\end{equation}

It's conventional to use $\beta = -2E$ instead of the energy itself, for reasons that will be clear soon. Substituting $\beta$ into the first term, and using the identity $\bm x \cdot \dot{\bm x} = r \dot{r}$, we get the following expression:
\begin{equation}
\label{mu-e}
\mu \bm e = \left( \frac{\mu}{r} - \beta \right) \bm x - r \dot{r} \bm v = \left( \frac{\mu}{r} - \beta \right) \bm x - \frac{r'}{r} \bm x'
\end{equation}

This contains an $(r'/r) \bm x'$ term, which, when substituted it back into (\ref{eq-of-motion-s}), gives a particularly simple differential equation:
\begin{equation}
\label{eq-of-motion-best}
\bm x'' + \beta \bm x = -\mu \bm e
\end{equation}

\subsection{$f$ and $g$ Functions}

Since $\bm x$ is a vector, we want to pick a basis to represent it in. Since the initial position (we'll denote it $\bm x_0$) and the initial velocity ($\bm v_0$) determine the orbital plane, we'll use those two vectors. There are then some functions $f(s)$ and $g(s)$ such that
\begin{equation}
\bm x(s) = f(s) \bm x_0 + g(s) \bm v_0
\end{equation}

Conveniently, we also know the coefficients of $\mu \bm e$ in this basis, from (\ref{mu-e}). Applying this basis to (\ref{eq-of-motion-best})
\begin{align*}
\bm x'' + \beta \bm x &= -\mu \bm e \\
(f'' \bm x_0 + g'' \bm v_0) + (\beta f \bm x_0 + \beta g \bm v_0) &= -\left[ \left( \frac{\mu}{r_0} - \beta \right) \bm x_0 - r_0 \dot{r}_0 \bm v_0 \right] \\
(f'' + \beta f) \bm x_0 + (g'' + \beta g) \bm v_0 &= \left( \beta - \frac{\mu}{r_0} \right) \bm x_0 + r_0 \dot{r}_0 \bm v_0
\end{align*}

Since $\bm x_0$ and $\bm v_0$ are independent (in the general case), we can separately equate the coefficients on each basis vector:
\begin{equation}
\label{f-and-g-equations}
f'' + \beta f = \beta - \frac{\mu}{r_0}  \qquad  g'' + \beta g = r_0 \dot{r}_0
\end{equation}

We now have two uncoupled, second-order, linear differential equations. Solving these would give us the solution for $\bm x$, parameterized by $s$.

\subsection{Stumpff Functions}

To solve the inhomogeneous diffeqs in (\ref{f-and-g-equations}), we first have to solve the associated homogeneous equations. Fortunately, this equation has well-known solutions. Unfortunately, we have to separate out cases depending on the sign of $\beta$:
\begin{equation}
\label{homogeneous-solutions}
f(s) = g(s) = \begin{cases}
A \cos(\sqrt{\beta} s) + B \sin(\sqrt{\beta} s)     & \beta > 0 \\
A \cosh(\sqrt{-\beta} s) + B \sinh(\sqrt{-\beta} s) & \beta < 0 \\
A + B s                                  & \beta = 0 \\
\end{cases}
\end{equation}

We'd like to unify these cases, so that our universal variables are truly universal. We can do so with the help of \emph{Stumpff functions}. The $k$th Stumpff function is defined by the following series, which converges absolutely for all $x$:
\begin{equation}
c_k(x) = \frac{1}{k!} - \frac{x}{(k+2)!} + \frac{x^2}{(k+4)!} - \frac{x^3}{(k+6)!} + \cdots
= \sum_{i=0}^\infty \frac{(-x)^i}{(k+2i)!}
\end{equation}

With some thought, the series for $c_0$ and $c_1$ can be recognized, and are expressible in a nice-ish form. Furthermore, there's a recurrence relation between $c_k$ and $c_{k+2}$:
\begin{equation}
c_0(x) = \begin{cases}
\cos(\sqrt x)    & x > 0 \\
\cosh(\sqrt{-x}) & x < 0 \\
1                & x = 0 \\
\end{cases}
\end{equation}
\begin{equation}
c_1(x) = \begin{cases}
\sin(\sqrt x) / \sqrt x      & x > 0 \\
\sinh(\sqrt{-x}) / \sqrt{-x} & x < 0 \\
1                            & x = 0 \\
\end{cases}
\end{equation}
\begin{equation}
x c_{k+2}(x) = \frac{1}{k!} - c_k(x)
\end{equation}

Note that $c_0$ and $c_1$ are are quite similar to the solutions to our diffeq. In order to
get the actual solutions, we introduce the two-variable functions $G_k(\beta, s)$:
\begin{equation}
G_k(\beta, s) = s^k c_k(\beta s^2)
\end{equation}

Like the $c_k$, these are smooth functions, defined everywhere. Expanding the definition of $G_k$, we see that $G_0$ and $G_1$ form a basis for the solution space of $f'' + \beta f = 0$ (compare with (\ref{homogeneous-solutions})).
\begin{equation}
G_0(\beta, s) = c_0(\beta s^2) = \begin{cases}
\cos(\sqrt{\beta} s)    & \beta > 0 \\
\cosh(\sqrt{-\beta} s)  & \beta < 0 \\
1                       & \beta = 0 \\
\end{cases}
\end{equation}
\begin{equation}
G_1(\beta, s) = s c_1(\beta s^2) = \begin{cases}
\sin(\sqrt{\beta} s) / \sqrt \beta      & \beta > 0 \\
\sinh(\sqrt{-\beta} s) / \sqrt{-\beta}  & \beta < 0 \\
s                                       & \beta = 0 \\
\end{cases}
\end{equation}

The $G_k$ have two more nice properties, which will be useful later.
\begin{equation}
\der{}{s} G_{k+1} = G_k  \qquad G_k(\beta, 0) = 0 \textrm{ for } k > 0
\end{equation}

\textit{Aside: This may seem like sweeping the casework under the rug, but it isn't. The reason that this is acceptable is that $G_k(\beta, s)$ is an analytic function in both variables, and varying $\beta$ lets us smoothly transition between the cases. The casework here is only about how we \textbf{choose to express it} in elementary functions.}

\subsection{Solving for Initial Conditions}

Now that we have the solution set for the associated homogeneous diffeq of (\ref{f-and-g-equations}), we need to find any solution to the inhomogeneous equation. Conveniently, constants will work here:
\begin{equation}
f(s) = 1 - \frac{\mu}{\beta r_0}  \qquad  g(s) = \frac{r_0 \dot{r}_0}{\beta}
\end{equation}

So our solutions for $f$ and $g$ are of the form:
\begin{equation}
\label{general-solution-f}
f(s) = 1 - \frac{\mu}{\beta r_0} + A G_0(\beta, s) + B G_1(\beta, s)
\end{equation}
\begin{equation}
\label{general-solution-g}
g(s) = \frac{r_0 \dot{r}_0}{\beta} + C G_0(\beta, s) + D G_1(\beta, s)
\end{equation}
for some constants $A$, $B$, $C$, and $D$, determined by the initial conditions.

Our initial conditions are in terms of $\bm x$, but they can be converted into initial conditions on $f$ and $g$ without much fuss. Since $s$ is defined as an integral, we have total freedom to pick the initial value, and so we'll just say $s = 0$ at the start. By evaluating $\bm x = f \bm x_0 + g \bm v_0$ at $s = 0$, we immediately see that $f(0) = 1$ and $g(0) = 0$. Likewise, evaluating $\dot{\bm x} = \dot{f} \bm x_0 + \dot{g} \bm v_0$ at zero gives $\dot f(0) = 0$ and $\dot g(0) = 1$. Converting to $s$-derivatives, we get our initial conditions:
\begin{equation}
f(0) = 1 \qquad\qquad g(0) = 0
\end{equation}
\begin{equation*}
f'(0) = r_0 \dot{f}(0) = 0 \qquad g'(0) = r_0 \dot{g}(0) = r_0
\end{equation*}

Evaluating these equations at $s = 0$, we obtain the values of $A$, $C$, $B$, and $D$, respectively.
\begin{equation}
A = \frac{\mu}{\beta r_0} \qquad B = 0 \qquad C = -\frac{r_0 \dot{r}_0}{\beta} \qquad D = r_0
\end{equation}

Plugging back into (\ref{general-solution-f}) and (\ref{general-solution-g}) gives us our complete solutions for $f$ and $g$.
\begin{equation}
f(s) = \left( 1 - \frac{\mu}{\beta r_0} \right) + \frac{\mu}{\beta r_0} G_0(\beta, s)
\end{equation}
\begin{equation}
g(s) = \frac{r_0 \dot{r}_0}{\beta} - \frac{r_0 \dot{r}_0}{\beta} G_0(\beta, s) + r_0 G_1(\beta, s)
\end{equation}

These solutions have a $\beta$ in some denominators, and that could prove troublesome when $\beta = 0$.
Fortunately, substituting $G_0 = 1 - \beta G_2$ lets us eliminate these denominators:
\begin{equation}
\label{solution-for-position}
f(s) = 1 - \frac{\mu}{r_0} G_2(\beta, s)
\qquad
g(s) = r_0 G_1(\beta, s) + r_0 \dot{r}_0 G_2(\beta, s)
\end{equation}

Together the equations in (\ref{solution-for-position}) give us the position for any value of $s$. To get the velocity, we'll also have to take the time derivative (not the $s$-derivative!). Since $\der{}{s} G_{k+1} = G_k$, we have $\der{}{t} G_{k+1} = \frac{1}{r} G_k$, giving:
\begin{equation}
\label{solution-for-velocity}
\dot f(s) = - \frac{\mu}{r r_0} G_1(\beta, s)
\qquad
\dot g(s) = \frac{r_0}{r} G_0(\beta, s) + \frac{r_0}{r} \dot{r}_0 G_1(\beta, s)
\end{equation}

At this point, we can now compute $\bm x$ and $\bm v$ at any given $s$. It remains to connect
$s$ to $t$.

\subsection{Connecting Time and Anomaly}

Given a value of $t$, how do we convert it to a value of $s$? Recall the defining relation $\der{s}{t} = \frac{1}{r}$. Rearranging, we get that $\dd t = r ~ \dd s$, and if we know $r$ in terms of $s$, we can integrate.

We can express $r(s)$ in terms of our $G$-functions. Start with the equation $r' = r \dot{r} = \bm x \cdot \dot{\bm x}$, and take the time derivative of both sides. Then, apply the equations of motion (\ref{eq-of-motion-t}), and the definition of energy (\ref{eccentricity-and-energy}):
\begin{equation*}
\der{}{t} r' = \der{}{t} (\bm x \cdot \bm{\dot x}) = \bm x \cdot \bm{\ddot x} + \bm{\dot x} \cdot \bm{\dot x}
\end{equation*}
\begin{equation*}
\frac{r''}{r} = -\frac{\mu}{r^3} \bm x^2 + 2 \left(E + \frac{\mu}{r} \right) = \frac{\mu}{r} -\beta
\end{equation*}
\begin{equation}
r'' + \beta r = \mu
\end{equation}

We've already seen how to solve diffeqs of this form; we know that the general solution for $r(s)$ looks like $r(s) = A + B G_1(\beta, s) + C G_2(\beta, s)$ (note: we could use $G_0$ and $G_1$ here instead, but if we did, we'd have to clear $\beta$ from the denominator, just like before).

Evaluating this and its $s$-derivatives at $s = 0$, it's straightforward to find these constants:
\begin{equation}
A = r(0) = r_0 \qquad B = r'(0) = r_0 \dot{r}_0 \qquad C = r''(0) = \mu - \beta r_0
\end{equation}

This gives us a clean equation for $r(s)$:
\begin{equation}
r(s) = r_0 G_0(\beta, s) + r_0 \dot{r}_0 G_1(\beta, s) + \mu G_2(\beta, s)
\end{equation}

Integrating this with respect to $s$ bumps up the subscript on the $G_i$, giving us the desired link between $s$ and $t$:
\begin{equation}
\label{solution-for-time}
t = \int r(s)~\dd s = r_0 G_1(\beta, s) + r_0 \dot{r}_0 G_2(\beta, s) + \mu G_3(\beta, s) + C
\end{equation}

Since we pegged $s$ to zero at our initial conditions, we have that $C = t_0$, or the time at start. So if we want to advance the system by some $s$, we can update position and velocity using (\ref{solution-for-position}) and (\ref{solution-for-velocity}), and update time using (\ref{solution-for-time}).

As a side note, we can use this to simplify the $\dot g$ expression in (\ref{solution-for-velocity}):
\begin{equation}
\dot g(s) = 1 - \frac{\mu}{r} G_2(\beta, s)
\end{equation}

(TODO: can i do something similar for $g$?)

\subsection{Connecting Universal, Eccentric, and True Anomalies}

What exactly is $s$? It's some kind of time-like parameter that describes how far along its orbit a satellite is. It turns out that it bears a close relation to the eccentric anomaly, and could be thought of as a ``universal'' kind of anomaly.

\subsubsection*{Elliptical Orbits}

For elliptical orbits, the \emph{true anomaly} is the actual angle that a satellite makes with its focal axis, and is denoted by $\theta$. The \emph{mean anomaly} $M$ is an averaged measure of motion; if $t$ is the time elapsed since periapsis, and $T$ is the period of the orbit, $M = 2 \pi t / T$.

The \emph{eccentric anomaly} is somewhat of a hybrid of these two quantities. The important things for us to know are Kepler's equation, which relates it to the mean anomaly, and a relation to the true-anomaly:
\begin{equation}
\label{keplers-equation}
M = E - e \sin E
\end{equation}
\begin{equation}
\label{eccentric-anomaly}
\tan{\frac{E}{2}} = \sqrt{\frac{1-e}{1+e}} \tan{\frac{\theta}{2}}
\end{equation}

To connect $s$ to $E$, we will integrate $\der{s}{t} = \frac{1}{r}$, and miraculously, the $r$ and $t$ quantities will coincide into a single expression in $E$.

First, we expand $r$ using the polar form of an ellipse:
\begin{equation}
\label{integrate-ellipse}
s = \int \frac{\dd t}{r} = \int \frac{1 + e \cos \theta}{a (1-e^2)}~\dd t
\end{equation}

Taking the derivative of (\ref{keplers-equation}), we can switch our integration variable to $E$:
\begin{equation}
\der{E}{t} = \frac{2 \pi / T}{1 - e \cos E}
\end{equation}

Plugging it into (\ref{integrate-ellipse}), we get an integrand without time:
\begin{equation}
s = \frac{T / 2 \pi}{a (1-e^2)} \int (1 + e \cos \theta)(1 - e \cos E)~\dd E
\end{equation}

Lastly, we need to express $\cos \theta$ in terms of $E$. By applying several different half-angle formulas to (\ref{eccentric-anomaly}), and grinding away, we can get
\begin{equation}
\cos \theta = \frac{\cos E - e}{1 - e \cos E}
\end{equation}

which, when plugged back into the previous integral, gives
\begin{equation}
s = \frac{T / 2 \pi}{a(1 - e^2)} \int (1 - e^2)~\dd E = \frac{T}{2 \pi a} E = \frac{E}{\sqrt \beta}
\end{equation}
where the last equality comes from Kepler's third law.

\subsubsection*{Non-Elliptical Orbits}

Similarly, for hyperbolic orbits, $s = H/\sqrt{-\beta}$, where $H$ is the hyperbolic eccentric anomaly, related to the true anomaly by:
\begin{equation}
\label{hyperbolic-anomaly}
\tanh{\frac{H}{2}} = \sqrt{\frac{e-1}{e+1}} \tan{\frac{\theta}{2}}
\end{equation}

Lastly, we look at the parabola. The polar form of a parabola is $r = \frac{h^2/\mu}{1 + \cos \theta}$, and instead of Kepler's equation, we use Barker's equation:
\begin{equation}
\label{barker}
t = \frac{h^3}{2 \mu^2} (D + \frac{1}{3} D^3)
\end{equation}
where $D = \tan \frac{\theta}{2}$ and $h$ is the angular momentum.

Taking the derivative of (\ref{barker}), we can change our integral to be over $D$:
\begin{equation}
s = \frac{h}{2 \mu} \int (1 + \cos \theta)(1 + D^2)~\dd D
\end{equation}

Through double-angle identities, we rephrase $\cos \theta$ to be $(1 - D^2)/(1 + D^2)$, allowing us to simplify the integrand to a constant $2$, and so
\begin{equation}
\label{parabolic-anomaly}
s = \frac{h}{\mu} D = \frac{h}{\mu} \tan \frac{\theta}{2}
\end{equation}

In summary, when converting from true to universal anomaly, we first convert to eccentric/hyperbolic anomaly, using (\ref{eccentric-anomaly}) and (\ref{hyperbolic-anomaly}). Then we divide through by $\sqrt{\pm \beta}$ to get $s$. Parabolas are a special case, and are simply handled by (\ref{parabolic-anomaly}).

\subsection*{Anchoring to Zero}

Given an initial position and velocity, we can then advance the state forward by $s$, with $s = 0$ representing our initial state. However, we would also like to represent points on an orbit, in some uniform way. Much like with propagation, the classical approach involves treating parabolic, elliptic, and hyperbolic orbits differently. We will try to leverage our $s$ in this way.

A natural point, present on all orbits, is the periapsis. Other than on a circular orbit, this point is unique, so we'll use it for the initial conditions, at $s = 0$, and describe all other points on the orbit from there. There are simple formulas for the radius and velocity at periapsis, and this would give the following parameterization:
\[ f(s) = 1 - \frac{\mu}{r_p} G_2(\beta, s) \]
\[ g(s) = r_p G_1(\beta, s) + r_p \dot r_p G_2(\beta, s) = r_p G_1(\beta, s) \]
\[ t = r_p G_1(\beta, s) + r_p \dot{r}_p G_2(\beta, s) + \mu G_3(\beta, s) = r_p G_1(\beta, s) + \mu G_3(\beta, s) \]

But there's a major problem lurking here: collision orbits. For those orbits, $r_p = 0$ and $v_p = \infty$, and conversely, $f(s) = \infty$ and $g(s) = 0$. Since $\bm x(s) = f(s) \bm x_p + g(s) \bm v_p$, these $0 \times \infty$ terms resolve to something finite, so this isn't an irresolvable problem, but it does mean that we cannot use $r_p$ and $v_p$ themselves as the parameterizing constants.

Instead, we'll fall back to some of the classic orbital elements: $E$, $h$, and $e$. Technically only two are needed, but using three makes some of the algebra easier, and we'll reduce to two at the end.

We'll switch to a coordinate system where the $x$-axis points toward periapsis, and the $y$ axis points along the velocity vector. Then:
\[ x = r_p f(s) = r_p - \mu G_2(\beta, s) = \frac{h^2}{\mu (1+e)} - \mu G_2(\beta, s) \]
\[ y = v_p g(s) = r_p v_p G_1(\beta, s) = h G_1(\beta, s) \]
%TODO velocity
\[ \dot x = r_p \dot{f}(s) = - \frac{\mu}{r} G_1(\beta, s) \]
\[ \dot y = v_p \dot{g}(s) = \frac{v_p r_p}{r} (G_0(\beta, s) + \dot{r}_p G_1(\beta, s)) = \frac{h}{r} G_0(\beta, s) \]

By taking $x^2 + y^2$, we could find a formula for $r$ as a function of $s$, but there's an easier way. Since $r = a(1 - e \cos E)$, for elliptical orbits, we can convert that into an expression with Stumpff functions, and it should work out for all orbits:
\begin{align*}
r &= a(1 - e \cos E) \\
&= a(1-e) + ae(1 - \cos E) \\
&= r_p + ae (1 - c_0(s \sqrt{\beta})) \\
&= r_p + ae (1 - G_0(\beta s^2)) \\
&= r_p + ae \beta G_2(\beta s^2) \\
&= \frac{h^2}{\mu(1+e)} + \mu e G_2(\beta s^2)
\end{align*}

%TODO apparently the G functions have addition formulas?
% G_3(β,s+t) = G_3(β,s) + G_2(β,s) G_1(β,t) + G_1(β,s) G_2(β,t) + G_3(β,t)
% try comparing to cosine formulas???
% also try squared formulas

%TODO add the tan (theta/2) = (...s...) formula

%TODO add the recurrence relation for G, also clean up that section with "we can simplify g-dot"

%TODO I gotta find a way to get s from position and velocity... :|

\subsection*{Various Orbital Element Relations}

\[ e^2 - 2E \frac{h^2}{\mu^2} = 1 \qquad e = \sqrt{1 + 2E \frac{h^2}{\mu^2}} \qquad E = (e^2 - 1) \frac{\mu^2}{2h^2} \]

\[ \beta = -2E = \frac{\mu}{a} \]

\[ r_p = a(1-e) = \frac{-\mu}{2E}(1-e) = \frac{h^2}{\mu (1+e)} \]
\[ v_p = \frac{h}{r_p} = \frac{\mu(1+e)}{h} \qquad v_p^2 = \frac{h^2}{r_p^2} = \frac{\mu}{a} \frac{1+e}{1-e} \]

\[ r = \frac{h^2/\mu}{1 + e \cos \theta} = a (1 - e \cos E) = a (1 - e \cosh H) \]

For a parabola:
\[ E = 0 \quad e = 1 \quad h = \textrm{anything} \quad r_p = \frac{h^2}{2\mu} \quad v_p = \frac{2\mu}{h} \]

% TODO anomaly

\end{document}